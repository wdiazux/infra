# Obico ML API
#
# Machine learning service for failure detection.
# Running in CPU-only mode (slower but no GPU requirement).
apiVersion: apps/v1
kind: Deployment
metadata:
  name: obico-ml-api
  namespace: printing
  labels:
    app.kubernetes.io/name: obico-ml-api
    app.kubernetes.io/component: ml
    app.kubernetes.io/part-of: printing
spec:
  # Disabled: ML API image requires CUDA even in CPU mode
  # Enable when GPU is available and set HAS_GPU=True with nvidia runtime
  replicas: 0
  strategy:
    type: Recreate
  selector:
    matchLabels:
      app.kubernetes.io/name: obico-ml-api
  template:
    metadata:
      labels:
        app.kubernetes.io/name: obico-ml-api
        app.kubernetes.io/component: ml
        app.kubernetes.io/part-of: printing
    spec:
      containers:
        - name: ml-api
          image: ghcr.io/gabe565/obico/ml-api:latest
          ports:
            - name: http
              containerPort: 3333
              protocol: TCP
          env:
            - name: DEBUG
              value: "False"
            - name: FLASK_APP
              value: "server.py"
            # CPU-only mode
            - name: HAS_GPU
              value: "False"
          resources:
            requests:
              memory: 512Mi
            limits:
              memory: 2Gi
          livenessProbe:
            httpGet:
              path: /p/
              port: http
            initialDelaySeconds: 60
            periodSeconds: 30
            timeoutSeconds: 10
          readinessProbe:
            httpGet:
              path: /p/
              port: http
            initialDelaySeconds: 30
            periodSeconds: 10
