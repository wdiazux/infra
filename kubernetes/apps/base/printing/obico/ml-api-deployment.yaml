# Obico ML API
#
# Machine learning service for failure detection.
# Running in CPU mode due to CUDA 11.4 vs 12.x driver incompatibility.
# TODO: Build custom image with CUDA 12 support for GPU acceleration.
apiVersion: apps/v1
kind: Deployment
metadata:
  name: obico-ml-api
  namespace: printing
  labels:
    app.kubernetes.io/name: obico-ml-api
    app.kubernetes.io/component: ml
    app.kubernetes.io/part-of: printing
spec:
  replicas: 1
  strategy:
    type: Recreate
  selector:
    matchLabels:
      app.kubernetes.io/name: obico-ml-api
  template:
    metadata:
      labels:
        app.kubernetes.io/name: obico-ml-api
        app.kubernetes.io/component: ml
        app.kubernetes.io/part-of: printing
    spec:
      containers:
        - name: ml-api
          image: ghcr.io/gabe565/obico/ml-api:latest
          ports:
            - name: http
              containerPort: 3333
              protocol: TCP
          env:
            - name: DEBUG
              value: "False"
            - name: FLASK_APP
              value: "server.py"
            - name: HAS_GPU
              value: "False"
            # Hide CUDA devices to force CPU mode
            - name: CUDA_VISIBLE_DEVICES
              value: ""
            - name: NVIDIA_VISIBLE_DEVICES
              value: "void"
          resources:
            requests:
              memory: 512Mi
              cpu: 500m
            limits:
              memory: 4Gi
              cpu: 2000m
          livenessProbe:
            httpGet:
              path: /p/
              port: http
            initialDelaySeconds: 120
            periodSeconds: 30
            timeoutSeconds: 10
          readinessProbe:
            httpGet:
              path: /p/
              port: http
            initialDelaySeconds: 60
            periodSeconds: 10
